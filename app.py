"""Chainlit application for the coding agent."""
import chainlit as cl
from pathlib import Path
from typing import Optional
import os

from agents import CodingAgent
from config import settings
from utils import get_session_manager


# Global agent instance
agent: Optional[CodingAgent] = None
session_manager = get_session_manager()


@cl.on_chat_start
async def start():
    """Initialize the chat session."""
    global agent

    # í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì • UI
    settings_ui = await cl.ChatSettings(
        [
            cl.input_widget.TextInput(
                id="project_path",
                label="ğŸ“ í”„ë¡œì íŠ¸ ê²½ë¡œ",
                description="ë¶„ì„í•  í”„ë¡œì íŠ¸ì˜ ì ˆëŒ€ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”",
                initial=str(Path.cwd()),
                placeholder="/path/to/your/project"
            ),
            cl.input_widget.Switch(
                id="auto_analyze",
                label="ğŸ” ìë™ ë¶„ì„",
                description="í”„ë¡œì íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ë¶„ì„í•˜ê³  RAGì— ì¸ë±ì‹±",
                initial=True
            ),
            cl.input_widget.Switch(
                id="restore_session",
                label="ğŸ”„ ì„¸ì…˜ ë³µì›",
                description="ì´ì „ ì„¸ì…˜ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ ë³µì›",
                initial=True
            ),
        ]
    ).send()

    # ì‚¬ìš©ìê°€ ì„¤ì •í•œ í”„ë¡œì íŠ¸ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
    project_path = settings_ui.get("project_path", str(Path.cwd()))
    auto_analyze = settings_ui.get("auto_analyze", True)
    restore_session = settings_ui.get("restore_session", True)

    # ì„¸ì…˜ ë³µì› ì‹œë„
    session_data = None
    if restore_session and await session_manager.session_exists(project_path):
        session_data = await session_manager.load_session(project_path)
        await cl.Message(
            content=f"âœ… ì´ì „ ì„¸ì…˜ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!\n"
                   f"- ë§ˆì§€ë§‰ ì ‘ê·¼: {session_data.get('last_accessed', 'Unknown')}\n"
                   f"- ë¶„ì„ëœ íŒŒì¼: {session_data.get('analyzed_files_count', 0)}ê°œ"
        ).send()

    # CodingAgent ì´ˆê¸°í™”
    agent = CodingAgent(project_path=project_path)

    # ì„¸ì…˜ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë³µì›
    if session_data:
        # RAG ì¸ë±ìŠ¤ ê²½ë¡œ ì„¤ì •
        rag_index_path = session_data.get("rag_index_path")
        if rag_index_path and os.path.exists(rag_index_path):
            # TODO: RAG ì¸ë±ìŠ¤ ë¡œë“œ ë¡œì§ ì¶”ê°€
            pass

    # Get current LLM info
    llm_info = agent.get_llm_info()
    provider = llm_info["provider"]
    model = llm_info["model"]

    # í”„ë¡œì íŠ¸ ì •ë³´ í‘œì‹œ
    project_info = f"""# ğŸ¤– AI Coding Assistant

Welcome! I'm your AI coding assistant powered by **{provider}** ({model}).

## ğŸ“‚ ë¡œë“œëœ í”„ë¡œì íŠ¸
- **ê²½ë¡œ**: `{project_path}`
- **ì„¸ì…˜ ë³µì›**: {'âœ… í™œì„±í™”' if restore_session else 'âŒ ë¹„í™œì„±í™”'}
- **ìë™ ë¶„ì„**: {'âœ… í™œì„±í™”' if auto_analyze else 'âŒ ë¹„í™œì„±í™”'}

## ğŸ¯ Capabilities
- ğŸ“ **Local File Analysis**: I can read and understand your project files
- ğŸŒ **Web Search**: I can search for documentation and examples
- ğŸ“š **RAG Knowledge**: Upload docs for me to reference
- âš¡ **Code Execution**: I can run code to verify solutions
- ğŸ”„ **Multi-LLM**: Switch between Claude, OpenAI, Groq, and DeepInfra

## ğŸ’¡ Tips
- ì•„ë˜ ë²„íŠ¼ì„ í´ë¦­í•˜ê±°ë‚˜ ìì—°ì–´ë¡œ ì§ˆë¬¸í•˜ì„¸ìš”
- ëª…ë ¹ì–´ ëŒ€ì‹  **í€µ ì•¡ì…˜ ë²„íŠ¼**ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

Ready to help! What would you like to work on?
"""

    # í€µ ì•¡ì…˜ ë²„íŠ¼ ìƒì„±
    actions = [
        cl.Action(name="analyze", value="analyze", label="ğŸ“Š í”„ë¡œì íŠ¸ ë¶„ì„"),
        cl.Action(name="save_session", value="save_session", label="ğŸ’¾ ì„¸ì…˜ ì €ì¥"),
        cl.Action(name="upload_docs", value="upload_docs", label="ğŸ“¤ ë¬¸ì„œ ì—…ë¡œë“œ"),
        cl.Action(name="rag_stats", value="rag_stats", label="ğŸ“ˆ RAG í†µê³„"),
        cl.Action(name="switch_llm", value="switch_llm", label="ğŸ”„ LLM ì „í™˜"),
        cl.Action(name="show_sessions", value="show_sessions", label="ğŸ’¾ ì„¸ì…˜ ëª©ë¡"),
        cl.Action(name="clear_chat", value="clear_chat", label="ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”"),
        cl.Action(name="help", value="help", label="â“ ë„ì›€ë§"),
    ]

    await cl.Message(content=project_info, actions=actions).send()

    # ìë™ ë¶„ì„ ì‹¤í–‰
    if auto_analyze and Path(project_path).exists():
        await cl.Message(content="ğŸ” í”„ë¡œì íŠ¸ ìë™ ë¶„ì„ ì¤‘...").send()
        try:
            # í”„ë¡œì íŠ¸ ë¶„ì„
            analysis = await agent.analyze_project()

            # íŒŒì¼ íŠ¸ë¦¬ ìƒì„±
            file_tree = await generate_file_tree(project_path)

            # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
            result_msg = f"""# ğŸ“Š í”„ë¡œì íŠ¸ ë¶„ì„ ì™„ë£Œ!

{analysis}

## ğŸ“ íŒŒì¼ êµ¬ì¡°
```
{file_tree}
```

ì„¸ì…˜ì´ ìë™ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.
"""
            await cl.Message(content=result_msg).send()

            # ì„¸ì…˜ ì €ì¥
            await save_current_session(project_path, agent)

        except Exception as e:
            await cl.Message(content=f"âš ï¸ ìë™ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}").send()


async def generate_file_tree(project_path: str, max_depth: int = 3, max_files: int = 50) -> str:
    """
    í”„ë¡œì íŠ¸ íŒŒì¼ íŠ¸ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        project_path: í”„ë¡œì íŠ¸ ê²½ë¡œ
        max_depth: ìµœëŒ€ ê¹Šì´
        max_files: ìµœëŒ€ íŒŒì¼ ìˆ˜

    Returns:
        íŒŒì¼ íŠ¸ë¦¬ ë¬¸ìì—´
    """
    def build_tree(path: Path, prefix: str = "", depth: int = 0, file_count: list = [0]) -> list[str]:
        if depth > max_depth or file_count[0] >= max_files:
            return []

        tree_lines = []
        try:
            items = sorted(path.iterdir(), key=lambda x: (not x.is_dir(), x.name))

            # ìˆ¨ê²¨ì§„ íŒŒì¼/ë””ë ‰í† ë¦¬ ì œì™¸
            items = [item for item in items if not item.name.startswith('.')]

            # node_modules, __pycache__ ë“± ì œì™¸
            exclude = {'node_modules', '__pycache__', '.git', 'venv', 'env', '.venv', 'dist', 'build'}
            items = [item for item in items if item.name not in exclude]

            for i, item in enumerate(items):
                if file_count[0] >= max_files:
                    tree_lines.append(f"{prefix}... (íŒŒì¼ ìˆ˜ ì œí•œ ë„ë‹¬)")
                    break

                is_last = i == len(items) - 1
                current_prefix = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
                next_prefix = "    " if is_last else "â”‚   "

                if item.is_dir():
                    tree_lines.append(f"{prefix}{current_prefix}ğŸ“ {item.name}/")
                    tree_lines.extend(build_tree(item, prefix + next_prefix, depth + 1, file_count))
                else:
                    tree_lines.append(f"{prefix}{current_prefix}ğŸ“„ {item.name}")
                    file_count[0] += 1

        except PermissionError:
            tree_lines.append(f"{prefix}... (ê¶Œí•œ ì—†ìŒ)")

        return tree_lines

    root = Path(project_path)
    tree = [f"ğŸ“ {root.name}/"]
    tree.extend(build_tree(root))

    return "\n".join(tree)


async def save_current_session(project_path: str, agent: CodingAgent):
    """í˜„ì¬ ì„¸ì…˜ì„ ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        # ë¶„ì„ëœ íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘ (í–¥í›„ êµ¬í˜„)
        analyzed_files = []

        # ì„¸ì…˜ ë°ì´í„° ì €ì¥
        await session_manager.save_session(
            project_path=project_path,
            analyzed_files=analyzed_files,
            settings={
                "llm_provider": agent.get_llm_info()["provider"],
                "project_loaded": True
            }
        )

        # ë§ˆì§€ë§‰ ì•¡ì„¸ìŠ¤ ì‹œê°„ ì—…ë°ì´íŠ¸
        await session_manager.update_last_accessed(project_path)

    except Exception as e:
        print(f"ì„¸ì…˜ ì €ì¥ ì‹¤íŒ¨: {e}")


@cl.action_callback("analyze")
async def on_action_analyze(action: cl.Action):
    """í”„ë¡œì íŠ¸ ë¶„ì„ ë²„íŠ¼ í´ë¦­"""
    await handle_command("/analyze")

@cl.action_callback("save_session")
async def on_action_save_session(action: cl.Action):
    """ì„¸ì…˜ ì €ì¥ ë²„íŠ¼ í´ë¦­"""
    await handle_command("/save-session")

@cl.action_callback("upload_docs")
async def on_action_upload_docs(action: cl.Action):
    """ë¬¸ì„œ ì—…ë¡œë“œ ë²„íŠ¼ í´ë¦­"""
    await handle_command("/upload")

@cl.action_callback("rag_stats")
async def on_action_rag_stats(action: cl.Action):
    """RAG í†µê³„ ë²„íŠ¼ í´ë¦­"""
    await handle_command("/stats")

@cl.action_callback("switch_llm")
async def on_action_switch_llm(action: cl.Action):
    """LLM ì „í™˜ ë²„íŠ¼ í´ë¦­"""
    # LLM ì„ íƒ UI í‘œì‹œ
    res = await cl.AskActionMessage(
        content="ì–´ë–¤ LLMìœ¼ë¡œ ì „í™˜í•˜ì‹œê² ìŠµë‹ˆê¹Œ?",
        actions=[
            cl.Action(name="claude", value="claude", label="ğŸ¤– Claude (Anthropic)"),
            cl.Action(name="openai", value="openai", label="ğŸŸ¢ OpenAI GPT-4"),
            cl.Action(name="groq", value="groq", label="âš¡ Groq (ë¹ ë¦„)"),
            cl.Action(name="deepinfra", value="deepinfra", label="ğŸ’° DeepInfra (ì €ë ´)"),
        ],
    ).send()

    if res:
        await handle_command(f"/switch {res['value']}")

@cl.action_callback("claude")
async def on_llm_claude(action: cl.Action):
    await handle_command("/switch claude")

@cl.action_callback("openai")
async def on_llm_openai(action: cl.Action):
    await handle_command("/switch openai")

@cl.action_callback("groq")
async def on_llm_groq(action: cl.Action):
    await handle_command("/switch groq")

@cl.action_callback("deepinfra")
async def on_llm_deepinfra(action: cl.Action):
    await handle_command("/switch deepinfra")

@cl.action_callback("show_sessions")
async def on_action_show_sessions(action: cl.Action):
    """ì„¸ì…˜ ëª©ë¡ ë²„íŠ¼ í´ë¦­"""
    await handle_command("/sessions")

@cl.action_callback("clear_chat")
async def on_action_clear_chat(action: cl.Action):
    """ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼ í´ë¦­"""
    await handle_command("/clear-chat")

@cl.action_callback("help")
async def on_action_help(action: cl.Action):
    """ë„ì›€ë§ ë²„íŠ¼ í´ë¦­"""
    await handle_command("/help")


@cl.on_message
async def main(message: cl.Message):
    """Process incoming messages."""
    global agent

    if agent is None:
        await cl.Message(content="Error: Agent not initialized. Please refresh the page.").send()
        return

    user_message = message.content.strip()

    # Handle commands
    if user_message.startswith("/"):
        await handle_command(user_message)
        return

    # Check for special flags in message
    use_web = "search" in user_message.lower() or "documentation" in user_message.lower()
    analyze_project = "analyze" in user_message.lower() or "project structure" in user_message.lower()

    # Process message with streaming
    msg = cl.Message(content="")
    await msg.send()

    async for chunk in agent.process_message(
        user_message,
        stream=True,
        use_rag=True,
        use_web=use_web,
        analyze_project=analyze_project
    ):
        await msg.stream_token(chunk)

    await msg.update()


async def handle_command(command: str):
    """Handle special commands."""
    global agent

    parts = command.split(maxsplit=1)
    cmd = parts[0].lower()
    args = parts[1] if len(parts) > 1 else ""

    if cmd == "/help":
        help_msg = """# ğŸ“– Available Commands

## í”„ë¡œì íŠ¸ ê´€ë¦¬
- `/load-project` - í”„ë¡œì íŠ¸ ë‹¤ì‹œ ë¡œë“œ (í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨)
- `/save-session` - í˜„ì¬ ì„¸ì…˜ ì €ì¥
- `/sessions` - ì €ì¥ëœ ì„¸ì…˜ ëª©ë¡ ë³´ê¸°
- `/analyze` - Analyze current project structure

## LLM ê´€ë¦¬
- `/switch <provider>` - Switch LLM provider
  - Available: claude, openai, groq, deepinfra
  - Example: `/switch openai`
- `/current-llm` - Show current LLM provider

## ë¬¸ì„œ ë° ê²€ìƒ‰
- `/search <query>` - Search web for documentation
  - Example: `/search python asyncio tutorial`
- `/upload` - Upload documentation for RAG
- `/stats` - Show RAG statistics
- `/clear-docs` - Clear all uploaded documentation

## ê¸°íƒ€
- `/clear-chat` - Clear conversation history
- `/help` - Show this help message

## ğŸ’¡ íŒ
- í”„ë¡œì íŠ¸ ê²½ë¡œëŠ” ì´ˆê¸° í™”ë©´ì—ì„œ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ìë™ ë¶„ì„ì„ í™œì„±í™”í•˜ë©´ í”„ë¡œì íŠ¸ íŒŒì¼ì´ ìë™ìœ¼ë¡œ ì¸ë±ì‹±ë©ë‹ˆë‹¤
- ì„¸ì…˜ì€ ìë™ìœ¼ë¡œ ì €ì¥ë˜ë©° ë‹¤ìŒ ì ‘ì† ì‹œ ë³µì›ë©ë‹ˆë‹¤
"""
        await cl.Message(content=help_msg).send()

    elif cmd == "/switch":
        if not args:
            await cl.Message(content="Please specify a provider: claude, openai, groq, or deepinfra").send()
            return

        try:
            result = agent.switch_llm(args.lower())
            llm_info = agent.get_llm_info()
            await cl.Message(content=f"âœ… {result}\nModel: {llm_info['model']}").send()
        except Exception as e:
            await cl.Message(content=f"âŒ Error: {e}").send()

    elif cmd == "/current-llm":
        llm_info = agent.get_llm_info()
        msg = f"""**Current LLM Provider**
- Provider: {llm_info['provider']}
- Model: {llm_info['model']}
- API Key: {'âœ… Configured' if llm_info['has_api_key'] else 'âŒ Not configured'}
"""
        await cl.Message(content=msg).send()

    elif cmd == "/analyze":
        await cl.Message(content="ğŸ” Analyzing project...").send()
        try:
            analysis = await agent.analyze_project()
            await cl.Message(content=f"# Project Analysis\n\n{analysis}").send()
        except Exception as e:
            await cl.Message(content=f"âŒ Error analyzing project: {e}").send()

    elif cmd == "/search":
        if not args:
            await cl.Message(content="Please provide a search query").send()
            return

        await cl.Message(content=f"ğŸ” Searching for: {args}...").send()
        try:
            results = await agent.web_search.search_documentation(args)
            if results:
                msg = "# Search Results\n\n"
                for i, result in enumerate(results[:5], 1):
                    msg += f"{i}. **{result['title']}**\n"
                    msg += f"   {result['url']}\n"
                    msg += f"   {result['snippet']}\n\n"
                await cl.Message(content=msg).send()
            else:
                await cl.Message(content="No results found.").send()
        except Exception as e:
            await cl.Message(content=f"âŒ Error searching: {e}").send()

    elif cmd == "/upload":
        files = await cl.AskFileMessage(
            content="Please upload documentation files (PDF, DOCX, TXT, MD, code files)",
            accept=["text/plain", "application/pdf", "application/vnd.openxmlformats-officedocument.wordprocessingml.document", ".md", ".py", ".js", ".ts"],
            max_size_mb=10,
            max_files=10
        ).send()

        if files:
            await cl.Message(content=f"ğŸ“¤ Uploading {len(files)} file(s)...").send()
            total_added = 0

            for file in files:
                try:
                    count = await agent.add_document_to_rag(file.path)
                    total_added += count
                except Exception as e:
                    await cl.Message(content=f"âŒ Error processing {file.name}: {e}").send()

            await cl.Message(content=f"âœ… Added {total_added} document chunks to knowledge base").send()

    elif cmd == "/stats":
        stats = agent.get_rag_stats()
        msg = f"""# ğŸ“Š RAG Statistics

- Total documents: {stats['total_documents']}
- Unique sources: {stats['unique_sources']}
- File types: {', '.join(stats['file_types']) if stats['file_types'] else 'None'}

**Sources:**
"""
        for source in stats['sources'][:10]:
            msg += f"- {source}\n"

        await cl.Message(content=msg).send()

    elif cmd == "/clear-docs":
        agent.clear_rag()
        await cl.Message(content="âœ… Cleared all uploaded documentation").send()

    elif cmd == "/clear-chat":
        agent.clear_conversation()
        await cl.Message(content="âœ… Cleared conversation history").send()

    elif cmd == "/save-session":
        project_path = agent.project_path
        await cl.Message(content="ğŸ’¾ ì„¸ì…˜ ì €ì¥ ì¤‘...").send()
        try:
            await save_current_session(project_path, agent)
            await cl.Message(content=f"âœ… ì„¸ì…˜ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\nê²½ë¡œ: {project_path}").send()
        except Exception as e:
            await cl.Message(content=f"âŒ ì„¸ì…˜ ì €ì¥ ì‹¤íŒ¨: {e}").send()

    elif cmd == "/load-project":
        await cl.Message(content="ğŸ“‚ í”„ë¡œì íŠ¸ ë‹¤ì‹œ ë¡œë“œí•˜ë ¤ë©´ ìƒˆë¡œê³ ì¹¨(F5)í•˜ì„¸ìš”.").send()

    elif cmd == "/sessions":
        await cl.Message(content="ğŸ“Š ì €ì¥ëœ ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ ì¤‘...").send()
        try:
            sessions = await session_manager.list_sessions()
            if sessions:
                msg = "# ğŸ’¾ ì €ì¥ëœ ì„¸ì…˜ ëª©ë¡\n\n"
                for i, session in enumerate(sessions, 1):
                    msg += f"{i}. **{session.get('project_path', 'Unknown')}**\n"
                    msg += f"   - ë§ˆì§€ë§‰ ì ‘ê·¼: {session.get('last_accessed', 'Unknown')}\n"
                    msg += f"   - ë¶„ì„ëœ íŒŒì¼: {session.get('analyzed_files_count', 0)}ê°œ\n"
                    msg += f"   - ëŒ€í™” ê¸°ë¡: {session.get('history_count', 0)}ê°œ\n\n"
                await cl.Message(content=msg).send()
            else:
                await cl.Message(content="ì €ì¥ëœ ì„¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.").send()
        except Exception as e:
            await cl.Message(content=f"âŒ ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}").send()

    else:
        await cl.Message(content=f"Unknown command: {cmd}\nType /help for available commands").send()


@cl.on_settings_update
async def setup_agent(settings):
    """Handle settings updates."""
    global agent
    # Could update agent settings here if needed
    pass


if __name__ == "__main__":
    from chainlit.cli import run_chainlit
    run_chainlit(__file__)
