"""í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ê´€ë¦¬ ë„êµ¬

pytestë¥¼ ìë™ìœ¼ë¡œ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤.
ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ëŠ” AutoErrorFixerì™€ ì—°ë™í•˜ì—¬ ìë™ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""

import asyncio
import subprocess
import re
from pathlib import Path
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from enum import Enum


class TestStatus(Enum):
    """í…ŒìŠ¤íŠ¸ ìƒíƒœ"""
    PASSED = "passed"
    FAILED = "failed"
    ERROR = "error"
    SKIPPED = "skipped"


@dataclass
class TestResult:
    """ê°œë³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼"""
    test_name: str
    file_path: str
    status: TestStatus
    duration: float
    error_message: Optional[str] = None
    traceback: Optional[str] = None
    line_number: Optional[int] = None


@dataclass
class TestSummary:
    """ì „ì²´ í…ŒìŠ¤íŠ¸ ìš”ì•½"""
    total: int
    passed: int
    failed: int
    error: int
    skipped: int
    duration: float
    results: List[TestResult]


class TestRunner:
    """pytest ì‹¤í–‰ ë° ê²°ê³¼ ê´€ë¦¬

    pytestë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    """

    def __init__(self, project_path: str = "."):
        """
        Args:
            project_path: í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ
        """
        self.project_path = Path(project_path)

    async def run_tests(
        self,
        test_path: Optional[str] = None,
        verbose: bool = True,
        capture: bool = True,
        markers: Optional[List[str]] = None,
        timeout: int = 300
    ) -> TestSummary:
        """í…ŒìŠ¤íŠ¸ ì‹¤í–‰

        Args:
            test_path: í…ŒìŠ¤íŠ¸ íŒŒì¼/ë””ë ‰í† ë¦¬ ê²½ë¡œ (Noneì´ë©´ ì „ì²´)
            verbose: ìƒì„¸ ì¶œë ¥
            capture: ì¶œë ¥ ìº¡ì²˜ (Falseë©´ ì‹¤ì‹œê°„ ì¶œë ¥)
            markers: pytest ë§ˆì»¤ í•„í„° (ì˜ˆ: ["slow", "unit"])
            timeout: íƒ€ì„ì•„ì›ƒ (ì´ˆ)

        Returns:
            TestSummary: í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½
        """
        # pytest ëª…ë ¹ì–´ êµ¬ì„±
        cmd = ["pytest"]

        if test_path:
            cmd.append(str(test_path))

        # ì˜µì…˜
        if verbose:
            cmd.append("-v")

        if not capture:
            cmd.append("-s")

        # ë§ˆì»¤ í•„í„°
        if markers:
            for marker in markers:
                cmd.extend(["-m", marker])

        # JSON ë¦¬í¬íŠ¸ ì¶œë ¥ (íŒŒì‹±ìš©)
        cmd.append("--tb=short")
        cmd.append("--color=no")

        print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹¤í–‰: {' '.join(cmd)}")

        # pytest ì‹¤í–‰
        try:
            result = subprocess.run(
                cmd,
                cwd=str(self.project_path),
                capture_output=True,
                text=True,
                timeout=timeout
            )

            stdout = result.stdout
            stderr = result.stderr
            returncode = result.returncode

        except subprocess.TimeoutExpired:
            print(f"â±ï¸  í…ŒìŠ¤íŠ¸ íƒ€ì„ì•„ì›ƒ ({timeout}ì´ˆ)")
            return TestSummary(
                total=0, passed=0, failed=0, error=1, skipped=0,
                duration=timeout,
                results=[TestResult(
                    test_name="timeout",
                    file_path="",
                    status=TestStatus.ERROR,
                    duration=timeout,
                    error_message=f"Test execution timed out after {timeout} seconds"
                )]
            )

        # ê²°ê³¼ íŒŒì‹±
        summary = self._parse_pytest_output(stdout, stderr, returncode)

        return summary

    def _parse_pytest_output(
        self,
        stdout: str,
        stderr: str,
        returncode: int
    ) -> TestSummary:
        """pytest ì¶œë ¥ íŒŒì‹±"""

        results = []

        # ê°œë³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ íŒŒì‹±
        # íŒ¨í„´: test_file.py::test_name PASSED [10%]
        test_pattern = r'([^\s]+\.py)::([^\s]+)\s+(PASSED|FAILED|ERROR|SKIPPED)'

        for match in re.finditer(test_pattern, stdout):
            file_path = match.group(1)
            test_name = match.group(2)
            status_str = match.group(3)

            status = TestStatus[status_str]

            # ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ì˜ ì—ëŸ¬ ë©”ì‹œì§€ ì¶”ì¶œ
            error_message = None
            traceback = None
            line_number = None

            if status in [TestStatus.FAILED, TestStatus.ERROR]:
                error_info = self._extract_error_info(stdout, test_name)
                error_message = error_info.get("message")
                traceback = error_info.get("traceback")
                line_number = error_info.get("line_number")

            results.append(TestResult(
                test_name=test_name,
                file_path=file_path,
                status=status,
                duration=0.0,  # pytest verbose ëª¨ë“œì—ì„œ ì¶”ì¶œ ê°€ëŠ¥
                error_message=error_message,
                traceback=traceback,
                line_number=line_number
            ))

        # ìš”ì•½ ì •ë³´ íŒŒì‹±
        # íŒ¨í„´: === 1 failed, 2 passed in 0.50s ===
        summary_pattern = r'(?:(\d+)\s+failed)?.*?(?:(\d+)\s+passed)?.*?(?:(\d+)\s+error)?.*?(?:(\d+)\s+skipped)?.*?in\s+([\d.]+)s'

        summary_match = re.search(summary_pattern, stdout)

        if summary_match:
            failed = int(summary_match.group(1) or 0)
            passed = int(summary_match.group(2) or 0)
            error = int(summary_match.group(3) or 0)
            skipped = int(summary_match.group(4) or 0)
            duration = float(summary_match.group(5))
        else:
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
            passed = len([r for r in results if r.status == TestStatus.PASSED])
            failed = len([r for r in results if r.status == TestStatus.FAILED])
            error = len([r for r in results if r.status == TestStatus.ERROR])
            skipped = len([r for r in results if r.status == TestStatus.SKIPPED])
            duration = 0.0

        total = passed + failed + error + skipped

        return TestSummary(
            total=total,
            passed=passed,
            failed=failed,
            error=error,
            skipped=skipped,
            duration=duration,
            results=results
        )

    def _extract_error_info(self, output: str, test_name: str) -> Dict[str, Any]:
        """ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ì˜ ì—ëŸ¬ ì •ë³´ ì¶”ì¶œ"""

        # í…ŒìŠ¤íŠ¸ ì´ë¦„ ì´í›„ì˜ ë‚´ìš©ì—ì„œ ì—ëŸ¬ ì •ë³´ ì°¾ê¸°
        test_section_pattern = f'{test_name}.*?(?=\n[A-Z_]+|$)'
        test_section = re.search(test_section_pattern, output, re.DOTALL)

        if not test_section:
            return {}

        section_text = test_section.group(0)

        # ì—ëŸ¬ ë©”ì‹œì§€ ì¶”ì¶œ
        error_message = None
        error_match = re.search(r'E\s+(.+)', section_text)
        if error_match:
            error_message = error_match.group(1).strip()

        # Traceback ì¶”ì¶œ
        traceback = None
        tb_match = re.search(r'(Traceback.*?)(?=\n[A-Z_]+|$)', section_text, re.DOTALL)
        if tb_match:
            traceback = tb_match.group(1).strip()

        # ë¼ì¸ ë²ˆí˜¸ ì¶”ì¶œ
        line_number = None
        line_match = re.search(r':(\d+):', section_text)
        if line_match:
            line_number = int(line_match.group(1))

        return {
            "message": error_message,
            "traceback": traceback,
            "line_number": line_number
        }

    async def run_with_auto_fix(
        self,
        test_path: Optional[str] = None,
        error_fixer=None,
        max_retries: int = 2
    ) -> Dict[str, Any]:
        """í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ì‹¤íŒ¨ ì‹œ ìë™ ìˆ˜ì •

        Args:
            test_path: í…ŒìŠ¤íŠ¸ ê²½ë¡œ
            error_fixer: AutoErrorFixer ì¸ìŠ¤í„´ìŠ¤
            max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜

        Returns:
            ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        if not error_fixer:
            from agents import AutoErrorFixer
            from llm import LLMManager
            from tools import FileOperations

            error_fixer = AutoErrorFixer(
                LLMManager(),
                FileOperations(),
                max_retries=max_retries
            )

        attempt = 0
        fix_history = []

        while attempt <= max_retries:
            print(f"\n{'='*60}")
            print(f"ğŸ”„ í…ŒìŠ¤íŠ¸ ì‹œë„ {attempt + 1}/{max_retries + 1}")
            print(f"{'='*60}\n")

            # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
            summary = await self.run_tests(test_path)

            # ì„±ê³µ ì‹œ ì¢…ë£Œ
            if summary.failed == 0 and summary.error == 0:
                print(f"\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! ({summary.passed}/{summary.total})")
                return {
                    "success": True,
                    "attempts": attempt + 1,
                    "summary": summary,
                    "fixes": fix_history
                }

            # ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ ì¶œë ¥
            print(f"\nâŒ ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸: {summary.failed + summary.error}ê°œ")

            failed_tests = [
                r for r in summary.results
                if r.status in [TestStatus.FAILED, TestStatus.ERROR]
            ]

            for test in failed_tests:
                print(f"   - {test.test_name}: {test.error_message}")

            # ë§ˆì§€ë§‰ ì‹œë„ì˜€ìœ¼ë©´ ì¢…ë£Œ
            if attempt >= max_retries:
                print(f"\nâš ï¸  ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ë„ë‹¬")
                break

            # ê° ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ì— ëŒ€í•´ ìë™ ìˆ˜ì • ì‹œë„
            print(f"\nğŸ”§ ìë™ ìˆ˜ì • ì‹œë„...\n")

            for test in failed_tests:
                if not test.file_path:
                    continue

                # í…ŒìŠ¤íŠ¸ íŒŒì¼ ì½ê¸°
                test_file = self.project_path / test.file_path

                if not test_file.exists():
                    print(f"   âš ï¸  íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {test_file}")
                    continue

                with open(test_file, 'r') as f:
                    code = f.read()

                # ì—ëŸ¬ ê°ì²´ ìƒì„± (ëª¨ì˜)
                error = Exception(test.error_message or "Test failed")

                # ìë™ ìˆ˜ì •
                try:
                    fix_result = await error_fixer.auto_fix(
                        error=error,
                        code=code,
                        file_path=str(test_file),
                        executor=None
                    )

                    if fix_result["success"]:
                        print(f"   âœ… {test.test_name} ìˆ˜ì • ì™„ë£Œ")
                        fix_history.append({
                            "test": test.test_name,
                            "attempt": attempt + 1,
                            "success": True
                        })
                    else:
                        print(f"   âŒ {test.test_name} ìˆ˜ì • ì‹¤íŒ¨")
                        fix_history.append({
                            "test": test.test_name,
                            "attempt": attempt + 1,
                            "success": False
                        })

                except Exception as e:
                    print(f"   âŒ ìˆ˜ì • ì¤‘ ì˜¤ë¥˜: {e}")

            attempt += 1

        # ìµœì¢… ì‹¤íŒ¨
        return {
            "success": False,
            "attempts": attempt,
            "summary": summary,
            "fixes": fix_history,
            "message": f"Failed tests after {attempt} attempts"
        }

    def get_coverage(self, test_path: Optional[str] = None) -> Optional[float]:
        """ì½”ë“œ ì»¤ë²„ë¦¬ì§€ ì¸¡ì •

        pytest-covê°€ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

        Returns:
            ì»¤ë²„ë¦¬ì§€ í¼ì„¼íŠ¸ (0-100)
        """
        cmd = ["pytest", "--cov", "--cov-report=term-missing"]

        if test_path:
            cmd.append(str(test_path))

        try:
            result = subprocess.run(
                cmd,
                cwd=str(self.project_path),
                capture_output=True,
                text=True,
                timeout=300
            )

            # ì»¤ë²„ë¦¬ì§€ í¼ì„¼íŠ¸ ì¶”ì¶œ
            # TOTAL   100   10   90%
            coverage_pattern = r'TOTAL\s+\d+\s+\d+\s+(\d+)%'
            match = re.search(coverage_pattern, result.stdout)

            if match:
                return float(match.group(1))

        except (subprocess.TimeoutExpired, FileNotFoundError):
            pass

        return None


# í—¬í¼ í•¨ìˆ˜

async def run_tests(test_path: Optional[str] = None, **kwargs) -> TestSummary:
    """í¸ì˜ í•¨ìˆ˜: í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    runner = TestRunner()
    return await runner.run_tests(test_path, **kwargs)


async def run_tests_with_fix(
    test_path: Optional[str] = None,
    error_fixer=None,
    max_retries: int = 2
) -> Dict[str, Any]:
    """í¸ì˜ í•¨ìˆ˜: í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ìë™ ìˆ˜ì •"""
    runner = TestRunner()
    return await runner.run_with_auto_fix(test_path, error_fixer, max_retries)
